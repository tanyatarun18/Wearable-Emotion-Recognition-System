{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IWgUZRdtXdgq",
        "outputId": "511a5486-b64a-4d94-8a0c-7902674961c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Drive mounted successfully.\n",
            "Dataset path found: /content/drive/MyDrive/WESAD\n",
            "\n",
            "Found 2 subject data files.\n",
            "Example path: /content/drive/MyDrive/WESAD/S16/S16.pkl\n",
            "\n",
            "Processing data and creating windows for all subjects...\n",
            "  - Processing S16...\n",
            "    - Added 148 windows for S16\n",
            "  - Processing S8...\n",
            "    - Added 148 windows for S8\n",
            "\n",
            "Total windows created: 296\n",
            "Window shape (samples, features): (120, 6)\n",
            "Labels shape: (296,)\n",
            "Unique labels: [0 1 2]\n",
            "\n",
            "Scaling data...\n",
            "Splitting into training and testing sets...\n",
            "\n",
            "Training data shape: (236, 120, 6)\n",
            "Testing data shape: (60, 120, 6)\n",
            "\n",
            "Building CNN-LSTM model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ maxpool_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m1,984\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ maxpool_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,251</span> (426.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,251\u001b[0m (426.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,251</span> (426.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,251\u001b[0m (426.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Compiling and training model...\n",
            "Epoch 1/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5889 - loss: 0.9668 - val_accuracy: 0.7500 - val_loss: 0.5743\n",
            "Epoch 2/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.8240 - loss: 0.4543 - val_accuracy: 0.8667 - val_loss: 0.2192\n",
            "Epoch 3/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9188 - loss: 0.1572 - val_accuracy: 0.9833 - val_loss: 0.1077\n",
            "Epoch 4/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9802 - loss: 0.1275 - val_accuracy: 0.9500 - val_loss: 0.1548\n",
            "Epoch 5/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9532 - loss: 0.1452 - val_accuracy: 0.9667 - val_loss: 0.0773\n",
            "Epoch 6/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9841 - loss: 0.0534 - val_accuracy: 0.9667 - val_loss: 0.0882\n",
            "Epoch 7/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9729 - loss: 0.0720 - val_accuracy: 0.9667 - val_loss: 0.0562\n",
            "Epoch 8/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9973 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
            "Epoch 9/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9964 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
            "Epoch 10/10\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9833 - val_loss: 0.0575\n",
            "\n",
            "Model training complete.\n",
            "\n",
            "Test Accuracy: 98.33%\n",
            "\n",
            "Converting model to TensorFlow Lite format (with Select TF Ops for LSTM)...\n",
            "Saved artifact at '/tmp/tmpnr00tvy9'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 120, 6), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136588484723536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588484731600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353519888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353522000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353522576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353520848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353522384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353523344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136588353523536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model converted successfully.\n",
            "\n",
            "--- SUCCESS! ---\n",
            "Model saved successfully to your Google Drive at:\n",
            "/content/drive/MyDrive/WESAD/emotion_model.tflite\n",
            "File size: 135.73 KB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import mode\n",
        "from google.colab import drive\n",
        "from scipy.signal import resample  \n",
        "\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive: {e}\")\n",
        "\n",
        "\n",
        "dataset_drive_path = '/content/drive/MyDrive/WESAD'  \n",
        "\n",
        "if not os.path.exists(dataset_drive_path) or 'https:' in dataset_drive_path:\n",
        "    print(f\"--- ERROR ---\")\n",
        "    if 'https:' in dataset_drive_path:\n",
        "        print(\"The path looks like a URL. It must be a file path.\")\n",
        "        print(\"Please use the file browser on the left, right-click your folder, and 'Copy path'.\")\n",
        "    else:\n",
        "        print(f\"The path '{dataset_drive_path}' does not exist.\")\n",
        "    print(\"Please check the path and try again.\")\n",
        "else:\n",
        "    print(f\"Dataset path found: {dataset_drive_path}\")\n",
        "\n",
        "\n",
        "search_pattern = os.path.join(dataset_drive_path, '**', 'S*.pkl')\n",
        "subject_pkl_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "\n",
        "final_subject_files = []\n",
        "for pkl_path in subject_pkl_files:\n",
        "    file_name = os.path.basename(pkl_path)\n",
        "    parent_folder_name = os.path.basename(os.path.dirname(pkl_path))\n",
        "\n",
        "\n",
        "    if file_name.replace('.pkl', '') == parent_folder_name:\n",
        "        final_subject_files.append(pkl_path)\n",
        "\n",
        "if not final_subject_files:\n",
        "    print(f\"\\n--- ERROR ---\")\n",
        "    print(f\"Could not find any subject .pkl files (e.g., S2/S2.pkl) in the folder:\")\n",
        "    print(f\"{dataset_drive_path}\")\n",
        "    print(f\"Please check your 'dataset_drive_path' variable. Make sure it points to the folder containing S2, S3, etc.\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(final_subject_files)} subject data files.\")\n",
        "    print(\"Example path:\", final_subject_files[0])\n",
        "\n",
        "\n",
        "\n",
        "def process_subject_data(subject_data):\n",
        "    \"\"\"Extracts, resamples, and combines wrist data for one subject.\"\"\"\n",
        "\n",
        "    if 'wrist' not in subject_data['signal']:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        wrist_eda = subject_data['signal']['wrist']['EDA'].flatten()\n",
        "        wrist_temp = subject_data['signal']['wrist']['TEMP'].flatten()\n",
        "\n",
        "        target_len = len(wrist_eda)\n",
        "        if target_len == 0:\n",
        "            return None, None \n",
        "\n",
        "        wrist_acc = np.array(subject_data['signal']['wrist']['ACC'])\n",
        "        wrist_bvp = np.array(subject_data['signal']['wrist']['BVP']).flatten()\n",
        "        labels_raw = np.array(subject_data['label']).flatten()\n",
        "\n",
        "        acc_resampled = resample(wrist_acc, target_len)\n",
        "        bvp_resampled = resample(wrist_bvp, target_len)\n",
        "        temp_resampled = resample(wrist_temp, target_len) \n",
        "\n",
        "        \n",
        "        labels_resampled = resample(labels_raw, target_len)\n",
        "        labels_rounded = np.round(labels_resampled).astype(int)\n",
        "\n",
        "        features = np.hstack([\n",
        "            acc_resampled,                         \n",
        "            bvp_resampled.reshape(-1, 1),          \n",
        "            wrist_eda.reshape(-1, 1),              \n",
        "            temp_resampled.reshape(-1, 1)          \n",
        "        ])\n",
        "\n",
        "        labels = labels_rounded.flatten() \n",
        "\n",
        "        return features, labels\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    - Error processing signals: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def create_windows(data, labels, window_size_sec, overlap_sec, fs=4):\n",
        "    window_size = window_size_sec * fs  \n",
        "    overlap = overlap_sec * fs          \n",
        "    stride = window_size - overlap\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(0, len(data) - window_size, stride):\n",
        "        window_data = data[i : i + window_size]\n",
        "        window_labels = labels[i : i + window_size]\n",
        "\n",
        "        \n",
        "        label = mode(window_labels, keepdims=True)[0]\n",
        "\n",
        "        \n",
        "        if label in [1, 2, 3]:\n",
        "            X.append(window_data)\n",
        "            y.append(label[0]) \n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "all_X = []\n",
        "all_y = []\n",
        "\n",
        "\n",
        "WINDOW_SEC = 30\n",
        "OVERLAP_SEC = 15\n",
        "SAMPLING_RATE = 4 \n",
        "\n",
        "print(\"\\nProcessing data and creating windows for all subjects...\")\n",
        "\n",
        "for pkl_file_path in final_subject_files:\n",
        "    subject_id = os.path.basename(pkl_file_path).replace('.pkl', '')\n",
        "    print(f\"  - Processing {subject_id}...\")\n",
        "\n",
        "    try:\n",
        "        \n",
        "        with open(pkl_file_path, 'rb') as f:\n",
        "            subject_data = pickle.load(f, encoding='latin1')\n",
        "\n",
        "        features, labels = process_subject_data(subject_data)\n",
        "\n",
        "        if features is None or labels is None:\n",
        "            print(f\"    - SKIPPING {subject_id} (Missing wrist data or other error)\")\n",
        "            continue\n",
        "\n",
        "        \n",
        "        X_subject, y_subject = create_windows(\n",
        "            features, labels, WINDOW_SEC, OVERLAP_SEC, SAMPLING_RATE\n",
        "        )\n",
        "\n",
        "        if X_subject.shape[0] > 0:\n",
        "            all_X.append(X_subject)\n",
        "            all_y.append(y_subject)\n",
        "            print(f\"    - Added {X_subject.shape[0]} windows for {subject_id}\")\n",
        "        else:\n",
        "            print(f\"    - No valid windows (labels 1, 2, 3) found for {subject_id}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    - FAILED to process {subject_id}. Error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "if not all_X or not all_y:\n",
        "    print(\"\\n\\n--- CRITICAL ERROR ---\")\n",
        "    print(\"No data was successfully processed.\")\n",
        "    print(\"This could mean your 'dataset_drive_path' (STEP 2) is wrong,\")\n",
        "    print(\"or the subjects found do not contain valid wrist data or labels (1, 2, 3).\")\n",
        "    print(\"Please check your path and the data.\")\n",
        "    raise ValueError(\"No valid subject data found to create windows.\")\n",
        "\n",
        "\n",
        "X = np.concatenate(all_X, axis=0)\n",
        "y = np.concatenate(all_y, axis=0)\n",
        "\n",
        "\n",
        "y = y - 1\n",
        "\n",
        "print(f\"\\nTotal windows created: {X.shape[0]}\")\n",
        "print(f\"Window shape (samples, features): {X.shape[1:]}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Unique labels: {np.unique(y)}\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nScaling data...\")\n",
        "\n",
        "num_windows, num_samples, num_features = X.shape\n",
        "X_reshaped = X.reshape(-1, num_features)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled_reshaped = scaler.fit_transform(X_reshaped)\n",
        "\n",
        "X_scaled = X_scaled_reshaped.reshape(num_windows, num_samples, num_features)\n",
        "\n",
        "print(\"Splitting into training and testing sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "window_length = X_train.shape[1] \n",
        "num_features = X_train.shape[2]  \n",
        "num_classes = 3                  \n",
        "\n",
        "print(\"\\nBuilding CNN-LSTM model...\")\n",
        "\n",
        "model = Sequential([\n",
        "    \n",
        "    Input(shape=(window_length, num_features), name=\"input_layer\"),\n",
        "\n",
        "    Conv1D(filters=64, kernel_size=5, activation='relu', padding='same', name=\"conv1d_1\"),\n",
        "    MaxPooling1D(pool_size=2, name=\"maxpool_1\"),\n",
        "\n",
        "    LSTM(128, return_sequences=False, name=\"lstm_1\"),\n",
        "\n",
        "    Dense(64, activation='relu', name=\"dense_1\"),\n",
        "    Dense(num_classes, activation='softmax', name=\"output_layer\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nCompiling and training model...\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "print(\"\\nModel training complete.\")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nConverting model to TensorFlow Lite format (with Select TF Ops for LSTM)...\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,  \n",
        "    tf.lite.OpsSet.SELECT_TF_OPS     \n",
        "]\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "try:\n",
        "    tflite_model = converter.convert()\n",
        "    print(\"Model converted successfully.\")\n",
        "\n",
        "    \n",
        "    output_filename = os.path.join(dataset_drive_path, 'emotion_model.tflite')\n",
        "\n",
        "    try:\n",
        "        with open(output_filename, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        print(f\"\\n--- SUCCESS! ---\")\n",
        "        print(f\"Model saved successfully to your Google Drive at:\")\n",
        "        print(output_filename)\n",
        "        print(f\"File size: {os.path.getsize(output_filename) / 1024:.2f} KB\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- ERROR SAVING FILE ---\")\n",
        "        print(f\"Could not save model to {output_filename}\")\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Trying to save locally instead...\")\n",
        "        local_filename = 'emotion_model.tflite'\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "        print(f\"Successfully saved model locally as '{local_filename}'\")\n",
        "        print(\"You will need to download it manually from the Colab file browser.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- TFLITE CONVERSION FAILED ---\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"This can happen if TensorFlow versions are incompatible. Please check the runtime.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBslGN72jX9w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
